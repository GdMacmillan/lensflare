{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LensFlare\n",
    "\n",
    "LensFlare is an educational deep learning library for understanding neural networks. The code is based on work from the [Coursera deeplearning.ai course](https://www.coursera.org/specializations/deep-learning).\n",
    "\n",
    "This notebook demonstrates the TensorFlow 2 implementation using the low-level `GradientTape` API for explicit gradient computation.\n",
    "\n",
    "## Features\n",
    "- **Metal GPU acceleration** on Apple Silicon Macs\n",
    "- **Educational low-level API** showing explicit forward/backward propagation\n",
    "- **sklearn-style interface** with `fit()`, `predict()`, `transform()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lensflare import TfNNClassifier, load_moons_dataset, check_gpu_available, plot_decision_boundary\n",
    "\n",
    "# Check if Metal GPU is available (Apple Silicon)\n",
    "check_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Moons Dataset\n",
    "\n",
    "The moons dataset is a simple binary classification problem useful for visualizing decision boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (set plot=True to visualize)\n",
    "X_train, y_train = load_moons_dataset(n_samples=300, noise=0.2, seed=42, plot=True)\n",
    "print(f\"Data shape: X={X_train.shape}, y={y_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Train the Neural Network\n",
    "\n",
    "The `TfNNClassifier` uses TensorFlow 2's `GradientTape` for explicit gradient computation, making it ideal for educational purposes.\n",
    "\n",
    "### Parameters:\n",
    "- `layers_dims`: Network architecture `[input_size, hidden1, hidden2, ..., output_size]`\n",
    "- `optimizer`: `'gd'` (SGD), `'momentum'`, or `'adam'`\n",
    "- `lambd`: L2 regularization strength\n",
    "- `keep_prob`: Dropout keep probability (1.0 = no dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define network architecture: 2 inputs -> 64 -> 32 -> 16 -> 1 output\n",
    "layers_dims = [X_train.shape[0], 64, 32, 16, 1]\n",
    "\n",
    "# Create classifier with Adam optimizer and L2 regularization\n",
    "clf = TfNNClassifier(\n",
    "    layers_dims=layers_dims,\n",
    "    optimizer=\"adam\",\n",
    "    alpha=0.01,           # Learning rate\n",
    "    lambd=0.01,           # L2 regularization\n",
    "    keep_prob=0.9,        # Dropout (90% keep)\n",
    "    num_epochs=2000,\n",
    "    print_cost=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train, seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions and print accuracy\n",
    "y_pred_train = clf.transform(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Decision Boundary\n",
    "\n",
    "The decision boundary shows how the neural network separates the two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decision boundary\n",
    "plot_decision_boundary(clf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Training Cost\n",
    "\n",
    "Visualize how the loss decreased during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.plot_costs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Model Internals\n",
    "\n",
    "For educational purposes, you can inspect the trained weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the learned parameters\n",
    "for key, value in clf.parameters_.items():\n",
    "    print(f\"{key}: shape={value.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the NumPy Implementation\n",
    "\n",
    "LensFlare also includes a pure NumPy implementation for even more educational transparency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lensflare import NpNNClassifier\n",
    "\n",
    "# Create NumPy-based classifier\n",
    "np_clf = NpNNClassifier(\n",
    "    layers_dims=[X_train.shape[0], 32, 16, 1],\n",
    "    optimizer=\"adam\",\n",
    "    alpha=0.01,\n",
    "    lambd=0.01,\n",
    "    num_epochs=2000,\n",
    "    print_cost=True\n",
    ")\n",
    "\n",
    "np_clf.fit(X_train, y_train, seed=1)\n",
    "np_clf.transform(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
